{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3692b50f",
   "metadata": {},
   "source": [
    "## Silkworm Rearing Segmentation Notebook\n",
    "Sections:\n",
    "1 Imports\n",
    "2 Configuration\n",
    "3 Utility functions\n",
    "4 Data loading\n",
    "5 SAM model initialization\n",
    "6 Segmentation loop\n",
    "7 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Imports\n",
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98523fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sam_model_type       = \"vit_b\"\n",
    "sam_checkpoint_url   = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
    "sam_checkpoint_path  = \"sam_vit_b_01ec64.pth\"\n",
    "\n",
    "image_directory      = \"data/images\"\n",
    "number_of_samples    = 3\n",
    "\n",
    "fourier_radius       = 30\n",
    "green_hue_min        = 40\n",
    "green_hue_max        = 90\n",
    "green_saturation_boost = 1.5\n",
    "red_hue_low          = 20\n",
    "red_hue_high         = 160\n",
    "\n",
    "clahe_clip_limit     = 2.0\n",
    "clahe_tile_size      = (8, 8)\n",
    "min_mask_area        = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Utility functions\n",
    "def download_checkpoint(url, destination):\n",
    "    if not os.path.exists(destination):\n",
    "        import requests\n",
    "        print(\"Downloading SAM checkpoint…\")\n",
    "        response = requests.get(url, allow_redirects=True)\n",
    "        with open(destination, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Download complete\")\n",
    "\n",
    "def apply_gray_world(image):\n",
    "    img32 = image.astype(np.float32)\n",
    "    channel_means = img32.mean(axis=(0, 1))\n",
    "    scale = channel_means.mean() / (channel_means + 1e-6)\n",
    "    balanced = img32 * scale\n",
    "    return np.clip(balanced, 0, 255).astype(np.uint8)\n",
    "\n",
    "def high_pass_filter(gray_image, radius=fourier_radius):\n",
    "    h, w = gray_image.shape\n",
    "    cy, cx = h // 2, w // 2\n",
    "    dft = cv2.dft(gray_image.astype(np.float32), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    mask = np.ones((h, w, 2), np.uint8)\n",
    "    mask[cy - radius : cy + radius, cx - radius : cx + radius] = 0\n",
    "    fshift = dft_shift * mask\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "    img_back = cv2.idft(f_ishift)\n",
    "    mag = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n",
    "    return cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "def preprocess_image(image_rgb):\n",
    "    # white balance and contrast\n",
    "    balanced = apply_gray_world(image_rgb)\n",
    "    lab = cv2.cvtColor(balanced, cv2.COLOR_RGB2LAB)\n",
    "    L, A, B = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clahe_clip_limit, tileGridSize=clahe_tile_size)\n",
    "    L_eq = clahe.apply(L)\n",
    "    contrast = cv2.cvtColor(cv2.merge((L_eq, A, B)), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    # edge enhancement\n",
    "    gray = cv2.cvtColor(contrast, cv2.COLOR_RGB2GRAY)\n",
    "    hp = high_pass_filter(gray)\n",
    "    enhanced = cv2.addWeighted(contrast, 1.0, cv2.cvtColor(hp, cv2.COLOR_GRAY2RGB), 0.5, 0)\n",
    "\n",
    "    # hue‐based saturation boost\n",
    "    hsv = cv2.cvtColor(enhanced, cv2.COLOR_RGB2HSV).astype(np.float32)\n",
    "    H, S, V = hsv[..., 0], hsv[..., 1], hsv[..., 2]\n",
    "    green_zone = (H >= green_hue_min) & (H <= green_hue_max)\n",
    "    S[green_zone] *= green_saturation_boost\n",
    "    red_zone   = (H <= red_hue_low) | (H >= red_hue_high)\n",
    "    S[red_zone] *= 0.6\n",
    "    hsv[..., 1] = np.clip(S, 0, 255)\n",
    "\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def combine_and_filter_masks(masks, min_area=min_mask_area):\n",
    "    combined = np.zeros_like(masks[0][\"segmentation\"], dtype=np.uint8)\n",
    "    for m in masks:\n",
    "        seg = m[\"segmentation\"].astype(np.uint8)\n",
    "        if seg.sum() >= min_area:\n",
    "            combined |= seg\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90248b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Data loading\n",
    "assert os.path.isdir(image_directory), f\"{image_directory} not found\"\n",
    "all_images = [\n",
    "    fname for fname in os.listdir(image_directory)\n",
    "    if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "assert all_images, \"No images in directory\"\n",
    "random.shuffle(all_images)\n",
    "sampled_images = all_images[:number_of_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32656508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 SAM model initialization\n",
    "download_checkpoint(sam_checkpoint_url, sam_checkpoint_path)\n",
    "\n",
    "sam = sam_model_registry[sam_model_type](checkpoint=sam_checkpoint_path).to(device)\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=64,\n",
    "    crop_n_layers=1,\n",
    "    pred_iou_thresh=0.7,\n",
    "    stability_score_thresh=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3021291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IMG_2969.jpg\n"
     ]
    }
   ],
   "source": [
    "# 6 Segmentation loop\n",
    "for fname in sampled_images:\n",
    "    print(\"Processing\", fname)\n",
    "    bgr = cv2.imread(os.path.join(image_directory, fname))\n",
    "    if bgr is None:\n",
    "        print(f\"Skipping {fname}\")\n",
    "        continue\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    pre = preprocess_image(rgb)\n",
    "    masks = mask_generator.generate(pre)\n",
    "    if not masks:\n",
    "        print(\"No masks returned\")\n",
    "        continue\n",
    "\n",
    "    hsv_pre = cv2.cvtColor(pre, cv2.COLOR_RGB2HSV)\n",
    "    worm_mask = np.zeros_like(masks[0][\"segmentation\"], dtype=np.uint8)\n",
    "    leaf_mask = worm_mask.copy()\n",
    "\n",
    "    for m in masks:\n",
    "        seg = m[\"segmentation\"].astype(np.uint8)\n",
    "        if seg.sum() < min_mask_area:\n",
    "            continue\n",
    "        mean_hue = cv2.mean(hsv_pre[:, :, 0], mask=seg)[0]\n",
    "        if green_hue_min <= mean_hue <= green_hue_max:\n",
    "            leaf_mask |= seg\n",
    "        else:\n",
    "            worm_mask |= seg\n",
    "\n",
    "    # Visualization\n",
    "    overlay_w = rgb.copy()\n",
    "    overlay_w[worm_mask == 1] = (\n",
    "        overlay_w[worm_mask == 1] * 0.3 + np.array([255, 0, 0]) * 0.7\n",
    "    ).astype(np.uint8)\n",
    "    overlay_l = rgb.copy()\n",
    "    overlay_l[leaf_mask == 1] = (\n",
    "        overlay_l[leaf_mask == 1] * 0.3 + np.array([0, 255, 0]) * 0.7\n",
    "    ).astype(np.uint8)\n",
    "    combined = np.full(rgb.shape, 120, dtype=np.uint8)\n",
    "    combined[leaf_mask == 1] = [0, 255, 0]\n",
    "    combined[worm_mask == 1] = [255, 0, 0]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(22, 4))\n",
    "    for ax, img, title in zip(\n",
    "        axes,\n",
    "        [rgb, pre, overlay_w, overlay_l, combined],\n",
    "        [\"Original\", \"Preprocessed\", \"Worms\", \"Leaves\", \"Classes\"]\n",
    "    ):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_gpu)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
