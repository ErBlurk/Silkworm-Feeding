**Segmentation Approaches Comparison:**

All three notebooks share the same backbone and basic geometry: DINOv2 ViT-B/14 loaded via torch.hub, inputs resized/cropped to 518×518, a 37×37 token grid, and the same semantic routine—spectral clustering with τ≈0.12 followed by KMeans with k=3—to get exactly three semantic classes; peak separation for watershed is always 12 px. The basic notebook hard-codes the label mapping (cluster 0 = silkworms, the rest follow), runs instance segmentation only on that binary silkworm mask, and splits instances with distance transform + watershed, no pre-clustering stage at all, min_obj_size = 150 px, no notion of “instance clusters” (~N/A), no merge rule because only worms are instanced, three visualization panels (Original / Semantic / Instance), and an output dict of instance_masks, semantic_map, label_to_name_map, silkworm_count. Folder creation isn’t really emphasized, nothing is saved beyond plots, only a few hyperparameters are exposed (τ, n_classes, min_obj_size, etc.), naming is fragile because a cluster ID swap breaks it, there’s no pipeline name, code stays straightforward (simple classes), computational cost is moderate, and worms are counted right after watershed on the silkworm mask. The heuristic notebook keeps that entire flow but replaces the brittle manual label assignment with an HSV heuristic (lowest saturation = silkworms; hue≈60 = leaves; leftovers = background), so it’s more robust without changing the core algorithm; instance splitting is still only on worms, still no pre-groups, still 150 px min size, still no instance cluster count, same 12 px peak separation, same three classes. It adds early folder creation, still only plots are saved (no actual files unless extended), exposes essentially the same knobs plus implicit HSV thresholds, has no formal pipeline name, code is the same set of classes with an extra labeling function, cost remains moderate, and counting is still after the silkworm watershed. The advanced U2Seg notebook actually restructures the pipeline: it first over-segments class-agnostically with spectral clustering into many (~150, configurable) tiny “raw instances”, then applies distance transform + watershed after that clustering stage; it filters smaller blobs by default (min_obj_size = 100 px, configurable), then merges instances back to semantics with a majority-overlap vote so every instance is assigned a class. That introduces a real instance cluster count (~150), a merge rule that didn’t exist before, and a fourth panel (Original / Raw instances / Semantic / Final merged). Outputs are richer—raw_instances, classified_instances, category_counts, semantic_map, semantic_names—folders are created, file paths are prepared (still only plots unless you extend), many more hyperparameters are surfaced (separate τ / n_clusters for semantics vs instances, etc.), class naming uses the same HSV idea but the voting step adds extra stability, the whole thing is wrapped in a formal U2SegUnified pipeline with multiple specialized classes and a merger class (more modular and layered), computational cost is slightly higher thanks to that extra spectral clustering, and counting now happens after merging so any class can be counted, not just worms. In short: Basic = manual labels + worm-only instances, Heuristic = same pipeline but color-based auto labels, U2Seg = two-branch (instances + semantics) system that over-segments first, then merges, giving more automation, configurability, robustness, and structure at a modest extra compute cost.
**Classification On Seg Masks Approaches Comparison:**
